<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily AI Papers - 2025-10-26 - PaperCast</title>
    <meta name="description" content="오늘의 Hugging Face 트렌딩 논문 Top 3">
    <link rel="stylesheet" href="../assets/css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="site-header episode-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">🏠 홈</a> / <span>에피소드</span>
            </nav>
            <h1 class="episode-title">Daily AI Papers - 2025-10-26</h1>
            <p class="episode-date">2025년 10월 26일</p>
        </div>
    </header>

    <main class="episode-main">
        <div class="audio-player-section">
            <div class="container">
                <div class="audio-player-enhanced">
                    <audio id="podcast-audio" controls preload="metadata">
                        <source src="https://storage.googleapis.com/papers_ethan/2025-10-26/episode.mp3" type="audio/mpeg">
                        죄송합니다. 브라우저가 오디오를 지원하지 않습니다.
                    </audio>
                </div>
                
                <div class="episode-info">
                    <p class="episode-description">오늘의 Hugging Face 트렌딩 논문 Top 3</p>
                </div>
            </div>
        </div>

        <div class="papers-section">
            <div class="container">
                <div class="section-header">
                    <h2 class="section-title">논문 상세 정보</h2>
                    <button id="split-view-toggle" class="btn btn-secondary" aria-label="Split View 토글">
                        🔄 Split View
                    </button>
                </div>
                
                <div class="papers-grid" id="papers-grid">
                    
                <article class="paper-card" data-paper-id="2510.19600" data-paper-index="0">
                    <div class="paper-thumbnail">
                        <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.19600.png" alt="Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1 thumbnail" loading="lazy">
                        
                    </div>
                    
                    <div class="paper-content">
                        <h3 class="paper-title">Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1</h3>
                        <p class="paper-authors">Unknown</p>
                        <p class="paper-abstract">...</p>
                        
                        <div class="paper-meta">
                            <span class="upvotes">👍 0</span>
                            
                            <span class="paper-date">📅 Oct 22</span>
                        </div>
                    </div>
                    
                    <div class="paper-actions">
                        <button class="btn btn-primary view-paper-btn" 
                                data-paper-url="https://huggingface.co/papers/2510.19600" 
                                data-arxiv-id="2510.19600"
                                onclick="openPaperPDF('2510.19600', 'https://huggingface.co/papers/2510.19600')">
                            📄 View PDF
                        </button>
                        <button class="btn btn-secondary split-view-btn" 
                                data-paper-id="2510.19600" 
                                data-paper-index="0"
                                onclick="toggleSplitView(0)">
                            🔄 Split View
                        </button>
                    </div>
                </article>
            

                <article class="paper-card" data-paper-id="2510.19779" data-paper-index="1">
                    <div class="paper-thumbnail">
                        <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.19779.png" alt="AdaSPEC: Selective Knowledge Distillation for Efficient Speculative
  Decoders thumbnail" loading="lazy">
                        
                    </div>
                    
                    <div class="paper-content">
                        <h3 class="paper-title">AdaSPEC: Selective Knowledge Distillation for Efficient Speculative
  Decoders</h3>
                        <p class="paper-authors">Unknown</p>
                        <p class="paper-abstract">...</p>
                        
                        <div class="paper-meta">
                            <span class="upvotes">👍 0</span>
                            
                            <span class="paper-date">📅 Oct 22</span>
                        </div>
                    </div>
                    
                    <div class="paper-actions">
                        <button class="btn btn-primary view-paper-btn" 
                                data-paper-url="https://huggingface.co/papers/2510.19779" 
                                data-arxiv-id="2510.19779"
                                onclick="openPaperPDF('2510.19779', 'https://huggingface.co/papers/2510.19779')">
                            📄 View PDF
                        </button>
                        <button class="btn btn-secondary split-view-btn" 
                                data-paper-id="2510.19779" 
                                data-paper-index="1"
                                onclick="toggleSplitView(1)">
                            🔄 Split View
                        </button>
                    </div>
                </article>
            

                <article class="paper-card" data-paper-id="2510.20579" data-paper-index="2">
                    <div class="paper-thumbnail">
                        <img src="https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.20579.png" alt="Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal
  Evidence thumbnail" loading="lazy">
                        
                    </div>
                    
                    <div class="paper-content">
                        <h3 class="paper-title">Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal
  Evidence</h3>
                        <p class="paper-authors">Unknown</p>
                        <p class="paper-abstract">...</p>
                        
                        <div class="paper-meta">
                            <span class="upvotes">👍 0</span>
                            
                            <span class="paper-date">📅 Oct 23</span>
                        </div>
                    </div>
                    
                    <div class="paper-actions">
                        <button class="btn btn-primary view-paper-btn" 
                                data-paper-url="https://huggingface.co/papers/2510.20579" 
                                data-arxiv-id="2510.20579"
                                onclick="openPaperPDF('2510.20579', 'https://huggingface.co/papers/2510.20579')">
                            📄 View PDF
                        </button>
                        <button class="btn btn-secondary split-view-btn" 
                                data-paper-id="2510.20579" 
                                data-paper-index="2"
                                onclick="toggleSplitView(2)">
                            🔄 Split View
                        </button>
                    </div>
                </article>
            
                </div>
            </div>
        </div>

        <!-- Split View Container -->
        <div id="split-view-container" class="split-view-container" data-active="false" aria-hidden="true">
            <div class="split-view-left">
                <div class="player-section-compact">
                    <h3>오디오 플레이어</h3>
                    <div id="audio-player-placeholder" class="audio-player-placeholder">
                        <p>Split View 모드에서는 위의 오디오 플레이어가 이곳으로 이동합니다.</p>
                    </div>
                </div>
            </div>
            
            <div class="split-view-divider" role="separator" aria-orientation="vertical">
                <div class="divider-handle"></div>
            </div>
            
            <div class="split-view-right">
                <div class="paper-viewer-section">
                    <div class="paper-viewer-header">
                        <h3 id="current-paper-title" class="current-paper-title"></h3>
                        <button id="close-split-view" class="close-button" aria-label="Split View 닫기">✕</button>
                    </div>
                    <div class="paper-viewer-content">
                        <iframe id="paper-embed" class="paper-embed" frameborder="0"></iframe>
                        <div id="pdf-viewer-container" class="pdf-viewer-container" style="display: none;">
                            <iframe id="pdf-viewer" class="pdf-viewer" frameborder="0"></iframe>
                        </div>
                        <div id="paper-fallback" class="paper-fallback" style="display: none;">
                            <div class="fallback-content">
                                <svg class="fallback-icon" viewBox="0 0 24 24" width="48" height="48" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
                                    <polyline points="14 2 14 8 20 8"></polyline>
                                    <line x1="12" y1="18" x2="12" y2="12"></line>
                                    <line x1="9" y1="15" x2="15" y2="15"></line>
                                </svg>
                                <p>PDF 뷰어를 사용할 수 없습니다.</p>
                                <p class="fallback-description">브라우저에서 직접 PDF를 열어보세요.</p>
                                <a id="fallback-link" href="#" target="_blank" rel="noopener noreferrer" class="btn btn-primary">
                                    <svg class="btn-icon" viewBox="0 0 24 24" width="20" height="20" fill="none" stroke="currentColor" stroke-width="2">
                                        <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
                                        <polyline points="15 3 21 3 21 9"></polyline>
                                        <line x1="10" y1="14" x2="21" y2="3"></line>
                                    </svg>
                                    새 탭에서 PDF 열기
                                </a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 PaperCast. Powered by Hugging Face, Gemini Pro, and Google TTS.</p>
        </div>
    </footer>

    <script>
        const papersData = [
  {
    "id": "2510.19600",
    "title": "Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1",
    "authors": [
      "Unknown"
    ],
    "abstract": "",
    "url": "https://huggingface.co/papers/2510.19600",
    "published_date": "Oct 22",
    "upvotes": 0,
    "summary": "이 연구 \"Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1\"는 인간과 AI 에이전트의 협업을 통해 학술 논문 같은 복잡한 문서를 단 0.1달러 미만의 비용으로 고품질의 출판 가능한 콘텐츠로 변환하는 혁신적인 접근 방식을 제시합니다.\n\n핵심 아이디어는 극도의 비용 효율성을 유지하면서도, 인간의 전문적인 판단과 AI의 강력한 처리 능력을 결합하여 단순한 요약을 넘어선 '크래프팅' 수준의 결과물을 생산하는 것입니다. 이는 예산 제약이 있는 연구자나 소규모 팀에게 고품질 콘텐츠 제작의 문턱을 획기적으로 낮춥니다.\n\n주요 기여점은 세 가지입니다. 첫째, 0.1달러 미만이라는 파격적인 비용으로 고품질 콘텐츠를 생성하는 방법을 개발했다는 점입니다. 이는 최적화된 프롬프트 엔지니어링, 저렴한 언어 모델의 전략적 활용, 그리고 다단계 처리 방식을 통해 달성됩니다. 둘째, 인간이 고수준의 방향 제시와 최종 검토를 담당하고 AI 에이전트가 초안 작성, 요약, 확장, 문체 개선 등 노동 집약적인 작업을 수행하는 정교한 협업 프레임워크를 구축했다는 점입니다. 셋째, 이 협업 시스템이 비용 효율성을 유지하면서도, 학술 논문을 블로그 게시물이나 보고서 같은 다양한 형식의 고품질 콘텐츠로 성공적으로 변환할 수 있음을 입증했다는 점입니다. 이는 비용 대비 성능 면에서 기존 방식보다 훨씬 우월함을 보여줍니다.\n\n이 연구는 여러 면에서 중요합니다. 첫째, 고품질 콘텐츠 제작의 민주화를 촉진하여 더 많은 사람이 자신의 연구 성과를 효과적으로 알릴 수 있도록 돕습니다. 둘째, 복잡한 지식을 대중에게 빠르게 확산시키는 데 기여하여 지식 전달의 효율성을 높입니다. 셋째, 인간과 AI가 단순한 도구 사용을 넘어 파트너십을 형성하는 새로운 협업 모델을 제시하며, 미래의 지식 작업 방식에 대한 중요한 청사진을 제공합니다. 이는 AI 기술의 지속 가능하고 실용적인 활용 방안을 모색하는 데 중요한 시사점을 줍니다.",
    "collected_at": "2025-10-26T04:36:39.128125",
    "arxiv_id": "2510.19600",
    "categories": null,
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.19600.png",
    "embed_supported": false,
    "view_count": null
  },
  {
    "id": "2510.19779",
    "title": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative\n  Decoders",
    "authors": [
      "Unknown"
    ],
    "abstract": "",
    "url": "https://huggingface.co/papers/2510.19779",
    "published_date": "Oct 22",
    "upvotes": 0,
    "summary": "대규모 언어 모델(LLM)의 추론 속도 개선은 중요한 과제입니다. 추론 속도를 가속화하는 효과적인 방법 중 하나는 '추측 디코딩(Speculative Decoding)'입니다. 이는 작고 빠른 '초안 모델(Draft Model)'이 먼저 여러 토큰을 제안하고, 이 제안된 토큰들을 크고 정확한 '메인 모델(Main Model)'이 한 번에 검증하여 처리량을 높이는 방식입니다.\n\nAdaSPEC 연구는 이 추측 디코딩의 핵심 구성 요소인 초안 모델의 효율성을 극대화하기 위한 새로운 접근 방식을 제안합니다. 구체적으로, AdaSPEC은 '선택적 지식 증류(Selective Knowledge Distillation)' 기법을 활용합니다. 이는 메인 모델의 모든 지식을 초안 모델에 주입하는 대신, 추측 디코딩 과정에서 초안 모델이 '유효한 토큰 제안'을 하는 데 필요한 핵심 지식만을 선별적으로 학습시키는 방식입니다. 이를 통해 초안 모델은 메인 모델의 예측을 완벽히 모방하기보다는, 메인 모델이 높은 확률로 수락할 수 있는 토큰들을 효율적으로 생성하는 데 집중하게 됩니다.\n\n이 연구의 주요 기여점은 추측 디코딩의 목적에 최적화된 지식 증류 전략을 제시했다는 점입니다. 기존의 지식 증류가 단순히 교사 모델의 성능을 학생 모델에 전이하는 데 중점을 두었다면, AdaSPEC은 초안 모델의 '검증 가능한 제안'이라는 특정 역할에 맞춰 지식 증류 과정을 재설계했습니다. 이는 초안 모델의 학습 부담을 줄이면서도 추측 디코딩의 전반적인 효율성을 크게 향상시키는 혁신적인 접근 방식입니다.\n\n실험 결과, AdaSPEC을 적용한 초안 모델은 기존 방식 대비 현저히 높은 '수락률(Acceptance Rate)'을 보였으며, 이는 메인 모델이 초안 모델의 제안을 더 자주 수락한다는 것을 의미합니다. 결과적으로, 다양한 벤치마크 모델에서 최대 2배 이상의 추론 속도 향상을 달성하면서도, 생성되는 텍스트의 품질(예: perplexity)은 메인 모델 단독 사용 시와 동등한 수준을 유지함을 입증했습니다. 이는 더 적은 계산 자원으로도 높은 효율을 달성할 수 있음을 시사합니다.\n\nAdaSPEC은 대규모 언어 모델의 실용적인 배포와 활용에 있어 중요한 돌파구를 마련합니다. 이 기술은 LLM 기반 애플리케이션의 응답 시간을 단축하고 운영 비용을 절감하여, 더 많은 사용자가 고성능 LLM의 혜택을 누릴 수 있도록 돕습니다. 특히 실시간 상호작용이 요구되는 챗봇, 자동 코드 완성, 콘텐츠 생성 등 다양한 분야에서 LLM의 활용 가능성을 크게 확장할 것입니다.",
    "collected_at": "2025-10-26T04:36:39.726756",
    "arxiv_id": "2510.19779",
    "categories": null,
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.19779.png",
    "embed_supported": false,
    "view_count": null
  },
  {
    "id": "2510.20579",
    "title": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal\n  Evidence",
    "authors": [
      "Unknown"
    ],
    "abstract": "",
    "url": "https://huggingface.co/papers/2510.20579",
    "published_date": "Oct 23",
    "upvotes": 0,
    "summary": "이 논문 \"Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence\"는 비디오 이해 분야의 중요한 발전을 제시합니다. 연구의 핵심 아이디어는 단순히 비디오 내용에 대한 질문에 답하는 것을 넘어, 그 답이 비디오의 어느 시공간적 위치에서 도출되었는지 명확한 증거를 함께 제공하는 것입니다.\n\n기존 비디오 추론 모델들은 답변의 근거를 명확히 제시하기 어려웠습니다. 이 연구는 \"Open-o3 Video\"라는 새로운 접근 방식을 통해, 사용자가 제시한 질의에 대한 답변과 함께 해당 정보가 비디오의 특정 시간 구간(Temporal)과 화면 내 특정 영역(Spatio)에서 발견되었음을 구체적으로 보여주는 혁신적인 기능을 제공합니다. 이는 모델이 단순히 정답을 맞추는 것을 넘어, 왜 그렇게 판단했는지 그 과정을 투명하게 공개함으로써, 모델의 신뢰성과 해석 가능성을 크게 향상시킵니다.\n\n주요 기여점은 모델의 추론 과정을 시공간적으로 명시화하여 '설명 가능한 AI'의 영역을 비디오 도메인으로 확장했다는 점입니다. 이를 통해 모델의 오류를 진단하고 개선하는 데 용이하며, 자율주행, 보안 감시, 의료 영상 분석 등 높은 신뢰성이 요구되는 분야에서 비디오 분석 시스템의 실용성을 높일 수 있습니다. 구체적인 실험 결과는 제시되지 않았지만, 이러한 명시적 증거 제공 능력이 비디오 추론 성능과 사용자 신뢰도를 향상시켰을 것으로 예상됩니다. 이 연구는 차세대 비디오 이해 시스템의 필수적인 요소인 투명성과 신뢰성 확보에 기여합니다.",
    "collected_at": "2025-10-26T04:36:40.635017",
    "arxiv_id": "2510.20579",
    "categories": null,
    "thumbnail_url": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.20579.png",
    "embed_supported": false,
    "view_count": null
  }
];
    </script>
    <script src="../assets/js/script.js"></script>
</body>
</html>