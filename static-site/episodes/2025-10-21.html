<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily AI Papers - 2025-10-21 - PaperCast</title>
    <meta name="description" content="ì˜¤ëŠ˜ì˜ Hugging Face íŠ¸ë Œë”© ë…¼ë¬¸ Top 3">
    <link rel="stylesheet" href="../assets/css/styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="site-header episode-header">
        <div class="container">
            <nav class="breadcrumb">
                <a href="../index.html">ğŸ  í™ˆ</a> / <span>ì—í”¼ì†Œë“œ</span>
            </nav>
            <h1 class="episode-title">Daily AI Papers - 2025-10-21</h1>
            <p class="episode-date">2025ë…„ 10ì›” 20ì¼</p>
        </div>
    </header>

    <main class="episode-main">
        <div class="audio-player-section">
            <div class="container">
                <div class="audio-player-enhanced">
                    <audio id="podcast-audio" controls preload="metadata">
                        <source src="https://storage.googleapis.com/papers_ethan/2025-10-21/episode.mp3" type="audio/mpeg">
                        ì£„ì†¡í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì €ê°€ ì˜¤ë””ì˜¤ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                    </audio>
                </div>
                
                <div class="episode-info">
                    <p class="episode-description">ì˜¤ëŠ˜ì˜ Hugging Face íŠ¸ë Œë”© ë…¼ë¬¸ Top 3</p>
                </div>
            </div>
        </div>

        <div class="papers-section">
            <div class="container">
                <div class="section-header">
                    <h2 class="section-title">ë…¼ë¬¸ ìƒì„¸ ì •ë³´</h2>
                    <button id="split-view-toggle" class="btn btn-secondary" aria-label="Split View í† ê¸€">
                        ğŸ”„ Split View
                    </button>
                </div>
                
                <div class="papers-grid" id="papers-grid">
                    
                <article class="paper-card" data-paper-id="2510.15444" data-paper-index="0">
                    <div class="paper-thumbnail">
                        <img src="../assets/images/placeholder.png" alt="A Theoretical Study on Bridging Internal Probability and
  Self-Consistency for LLM Reasoning thumbnail" loading="lazy">
                        
                    </div>
                    
                    <div class="paper-content">
                        <h3 class="paper-title">A Theoretical Study on Bridging Internal Probability and
  Self-Consistency for LLM Reasoning</h3>
                        <p class="paper-authors">Zhi Zhou, Yuhao Tan, Zenan Li ì™¸ 4ëª…</p>
                        <p class="paper-abstract">Test-time scaling seeks to improve the reasoning performance of large
language models (LLMs) by adding computational resources. A prevalent approach
within the field is sampling-based test-time scalin...</p>
                        
                        <div class="paper-meta">
                            <span class="upvotes">ğŸ‘ 4</span>
                            
                            <span class="paper-date">ğŸ“… 2025-10-17</span>
                        </div>
                    </div>
                    
                    <div class="paper-actions">
                        <button class="btn btn-primary view-paper-btn" 
                                data-paper-url="https://huggingface.co/papers/2510.15444" 
                                data-arxiv-id=""
                                onclick="openPaperPDF('', 'https://huggingface.co/papers/2510.15444')">
                            ğŸ“„ View PDF
                        </button>
                        <button class="btn btn-secondary split-view-btn" 
                                data-paper-id="2510.15444" 
                                data-paper-index="0"
                                onclick="toggleSplitView(0)">
                            ğŸ”„ Split View
                        </button>
                    </div>
                </article>
            

                <article class="paper-card" data-paper-id="2510.15264" data-paper-index="1">
                    <div class="paper-thumbnail">
                        <img src="../assets/images/placeholder.png" alt="DriveGen3D: Boosting Feed-Forward Driving Scene Generation with
  Efficient Video Diffusion thumbnail" loading="lazy">
                        
                    </div>
                    
                    <div class="paper-content">
                        <h3 class="paper-title">DriveGen3D: Boosting Feed-Forward Driving Scene Generation with
  Efficient Video Diffusion</h3>
                        <p class="paper-authors">Weijie Wang, Jiagang Zhu, Zeyu Zhang ì™¸ 13ëª…</p>
                        <p class="paper-abstract">We present DriveGen3D, a novel framework for generating high-quality and
highly controllable dynamic 3D driving scenes that addresses critical
limitations in existing methodologies. Current approaches...</p>
                        
                        <div class="paper-meta">
                            <span class="upvotes">ğŸ‘ 1</span>
                            
                            <span class="paper-date">ğŸ“… 2025-10-16</span>
                        </div>
                    </div>
                    
                    <div class="paper-actions">
                        <button class="btn btn-primary view-paper-btn" 
                                data-paper-url="https://huggingface.co/papers/2510.15264" 
                                data-arxiv-id=""
                                onclick="openPaperPDF('', 'https://huggingface.co/papers/2510.15264')">
                            ğŸ“„ View PDF
                        </button>
                        <button class="btn btn-secondary split-view-btn" 
                                data-paper-id="2510.15264" 
                                data-paper-index="1"
                                onclick="toggleSplitView(1)">
                            ğŸ”„ Split View
                        </button>
                    </div>
                </article>
            

                <article class="paper-card" data-paper-id="2510.11288" data-paper-index="2">
                    <div class="paper-thumbnail">
                        <img src="../assets/images/placeholder.png" alt="Emergent Misalignment via In-Context Learning: Narrow in-context
  examples can produce broadly misaligned LLMs thumbnail" loading="lazy">
                        
                    </div>
                    
                    <div class="paper-content">
                        <h3 class="paper-title">Emergent Misalignment via In-Context Learning: Narrow in-context
  examples can produce broadly misaligned LLMs</h3>
                        <p class="paper-authors">Nikita Afonin, Nikita Andriyanov, Nikhil Bageshpura ì™¸ 8ëª…</p>
                        <p class="paper-abstract">Recent work has shown that narrow finetuning can produce broadly misaligned
LLMs, a phenomenon termed emergent misalignment (EM). While concerning, these
findings were limited to finetuning and activa...</p>
                        
                        <div class="paper-meta">
                            <span class="upvotes">ğŸ‘ 1</span>
                            
                            <span class="paper-date">ğŸ“… 2025-10-13</span>
                        </div>
                    </div>
                    
                    <div class="paper-actions">
                        <button class="btn btn-primary view-paper-btn" 
                                data-paper-url="https://huggingface.co/papers/2510.11288" 
                                data-arxiv-id=""
                                onclick="openPaperPDF('', 'https://huggingface.co/papers/2510.11288')">
                            ğŸ“„ View PDF
                        </button>
                        <button class="btn btn-secondary split-view-btn" 
                                data-paper-id="2510.11288" 
                                data-paper-index="2"
                                onclick="toggleSplitView(2)">
                            ğŸ”„ Split View
                        </button>
                    </div>
                </article>
            
                </div>
            </div>
        </div>

        <!-- Split View Container -->
        <div id="split-view-container" class="split-view-container" data-active="false" aria-hidden="true">
            <div class="split-view-left">
                <div class="player-section-compact">
                    <h3>ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´</h3>
                    <div id="audio-player-placeholder" class="audio-player-placeholder">
                        <p>Split View ëª¨ë“œì—ì„œëŠ” ìœ„ì˜ ì˜¤ë””ì˜¤ í”Œë ˆì´ì–´ê°€ ì´ê³³ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤.</p>
                    </div>
                </div>
            </div>
            
            <div class="split-view-divider" role="separator" aria-orientation="vertical">
                <div class="divider-handle"></div>
            </div>
            
            <div class="split-view-right">
                <div class="paper-viewer-section">
                    <div class="paper-viewer-header">
                        <h3 id="current-paper-title" class="current-paper-title"></h3>
                        <button id="close-split-view" class="close-button" aria-label="Split View ë‹«ê¸°">âœ•</button>
                    </div>
                    <div class="paper-viewer-content">
                        <iframe id="paper-embed" class="paper-embed" frameborder="0"></iframe>
                        <div id="pdf-viewer-container" class="pdf-viewer-container" style="display: none;">
                            <iframe id="pdf-viewer" class="pdf-viewer" frameborder="0"></iframe>
                        </div>
                        <div id="paper-fallback" class="paper-fallback" style="display: none;">
                            <div class="fallback-content">
                                <svg class="fallback-icon" viewBox="0 0 24 24" width="48" height="48" fill="none" stroke="currentColor" stroke-width="2">
                                    <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
                                    <polyline points="14 2 14 8 20 8"></polyline>
                                    <line x1="12" y1="18" x2="12" y2="12"></line>
                                    <line x1="9" y1="15" x2="15" y2="15"></line>
                                </svg>
                                <p>PDF ë·°ì–´ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</p>
                                <p class="fallback-description">ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ PDFë¥¼ ì—´ì–´ë³´ì„¸ìš”.</p>
                                <a id="fallback-link" href="#" target="_blank" rel="noopener noreferrer" class="btn btn-primary">
                                    <svg class="btn-icon" viewBox="0 0 24 24" width="20" height="20" fill="none" stroke="currentColor" stroke-width="2">
                                        <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path>
                                        <polyline points="15 3 21 3 21 9"></polyline>
                                        <line x1="10" y1="14" x2="21" y2="3"></line>
                                    </svg>
                                    ìƒˆ íƒ­ì—ì„œ PDF ì—´ê¸°
                                </a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <footer class="site-footer">
        <div class="container">
            <p>&copy; 2025 PaperCast. Powered by Hugging Face, Gemini Pro, and Google TTS.</p>
        </div>
    </footer>

    <script>
        const papersData = [
  {
    "id": "2510.15444",
    "title": "A Theoretical Study on Bridging Internal Probability and\n  Self-Consistency for LLM Reasoning",
    "authors": [
      "Zhi Zhou",
      "Yuhao Tan",
      "Zenan Li",
      "Yuan Yao",
      "Lan-Zhe Guo",
      "Yu-Feng Li",
      "Xiaoxing Ma"
    ],
    "abstract": "Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field is sampling-based test-time scaling methods, which enhance\nreasoning by generating multiple reasoning paths for a given input during\ninference. However, despite its practical success, the theoretical foundations\nremain underexplored. In this paper, we provide the first theoretical framework\nfor analyzing sampling-based test-time scaling methods, grounded in the\nperspective of confidence estimation. Based on the framework, we analyze two\ndominant paradigms: self-consistency and perplexity, and reveal key\nlimitations: self-consistency suffers from high estimation error while\nperplexity exhibits substantial modeling error and possible degradation of the\nestimation error convergence. To address these limitations, we introduce RPC, a\nhybrid method that leverages our theoretical insights through two key\ncomponents: Perplexity Consistency and Reasoning Pruning. Perplexity\nConsistency combines the strengths of self-consistency and perplexity, boosting\nthe convergence rate of estimation error from linear to exponential while\npreserving model error. Reasoning Pruning prevents degradation by eliminating\nlow-probability reasoning paths. Both theoretical analysis and empirical\nresults across seven benchmark datasets demonstrate that RPC has a strong\npotential for reducing reasoning error. Notably, RPC achieves reasoning\nperformance comparable to self-consistency while not only enhancing confidence\nreliability but also reducing sampling costs by 50%. The code and resources are\navailable at https://wnjxyk.github.io/RPC.",
    "url": "https://huggingface.co/papers/2510.15444",
    "published_date": "2025-10-17",
    "upvotes": 4,
    "summary": "'A Theoretical Study on Bridging Internal Probability and\n  Self-Consistency for LLM Reasoning'ì€(ëŠ”) Zhi Zhou, Yuhao Tan, Zenan Li ì™¸ 4ëª…ì˜ ì—°êµ¬ì…ë‹ˆë‹¤. Test-time scaling seeks to improve the reasoning performance of large\nlanguage models (LLMs) by adding computational resources. A prevalent approach\nwithin the field is sampling-based test-time scalin...",
    "collected_at": "2025-10-20T16:06:55.471384",
    "arxiv_id": null,
    "categories": null,
    "thumbnail_url": null,
    "embed_supported": null,
    "view_count": null
  },
  {
    "id": "2510.15264",
    "title": "DriveGen3D: Boosting Feed-Forward Driving Scene Generation with\n  Efficient Video Diffusion",
    "authors": [
      "Weijie Wang",
      "Jiagang Zhu",
      "Zeyu Zhang",
      "Xiaofeng Wang",
      "Zheng Zhu",
      "Guosheng Zhao",
      "Chaojun Ni",
      "Haoxiao Wang",
      "Guan Huang",
      "Xinze Chen",
      "Yukun Zhou",
      "Wenkang Qin",
      "Duochao Shi",
      "Haoyun Li",
      "Guanghong Jia",
      "Jiwen Lu"
    ],
    "abstract": "We present DriveGen3D, a novel framework for generating high-quality and\nhighly controllable dynamic 3D driving scenes that addresses critical\nlimitations in existing methodologies. Current approaches to driving scene\nsynthesis either suffer from prohibitive computational demands for extended\ntemporal generation, focus exclusively on prolonged video synthesis without 3D\nrepresentation, or restrict themselves to static single-scene reconstruction.\nOur work bridges this methodological gap by integrating accelerated long-term\nvideo generation with large-scale dynamic scene reconstruction through\nmultimodal conditional control. DriveGen3D introduces a unified pipeline\nconsisting of two specialized components: FastDrive-DiT, an efficient video\ndiffusion transformer for high-resolution, temporally coherent video synthesis\nunder text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a\nfeed-forward reconstruction module that rapidly builds 3D Gaussian\nrepresentations across time, ensuring spatial-temporal consistency. Together,\nthese components enable real-time generation of extended driving videos (up to\n424times800 at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM\nof 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining\nparameter efficiency.",
    "url": "https://huggingface.co/papers/2510.15264",
    "published_date": "2025-10-16",
    "upvotes": 1,
    "summary": "'DriveGen3D: Boosting Feed-Forward Driving Scene Generation with\n  Efficient Video Diffusion'ì€(ëŠ”) Weijie Wang, Jiagang Zhu, Zeyu Zhang ì™¸ 13ëª…ì˜ ì—°êµ¬ì…ë‹ˆë‹¤. We present DriveGen3D, a novel framework for generating high-quality and\nhighly controllable dynamic 3D driving scenes that addresses critical\nlimitations in existing methodologies. Current approaches...",
    "collected_at": "2025-10-20T16:06:55.471473",
    "arxiv_id": null,
    "categories": null,
    "thumbnail_url": null,
    "embed_supported": null,
    "view_count": null
  },
  {
    "id": "2510.11288",
    "title": "Emergent Misalignment via In-Context Learning: Narrow in-context\n  examples can produce broadly misaligned LLMs",
    "authors": [
      "Nikita Afonin",
      "Nikita Andriyanov",
      "Nikhil Bageshpura",
      "Kyle Liu",
      "Kevin Zhu",
      "Sunishchal Dev",
      "Ashwinee Panda",
      "Alexander Panchenko",
      "Oleg Rogov",
      "Elena Tutubalina",
      "Mikhail Seleznyov"
    ],
    "abstract": "Recent work has shown that narrow finetuning can produce broadly misaligned\nLLMs, a phenomenon termed emergent misalignment (EM). While concerning, these\nfindings were limited to finetuning and activation steering, leaving out\nin-context learning (ICL). We therefore ask: does EM emerge in ICL? We find\nthat it does: across three datasets, three frontier models produce broadly\nmisaligned responses at rates between 2% and 17% given 64 narrow in-context\nexamples, and up to 58% with 256 examples. We also examine mechanisms of EM by\neliciting step-by-step reasoning (while leaving in-context examples unchanged).\nManual analysis of the resulting chain-of-thought shows that 67.5% of\nmisaligned traces explicitly rationalize harmful outputs by adopting a reckless\nor dangerous ''persona'', echoing prior results on finetuning-induced EM.",
    "url": "https://huggingface.co/papers/2510.11288",
    "published_date": "2025-10-13",
    "upvotes": 1,
    "summary": "'Emergent Misalignment via In-Context Learning: Narrow in-context\n  examples can produce broadly misaligned LLMs'ì€(ëŠ”) Nikita Afonin, Nikita Andriyanov, Nikhil Bageshpura ì™¸ 8ëª…ì˜ ì—°êµ¬ì…ë‹ˆë‹¤. Recent work has shown that narrow finetuning can produce broadly misaligned\nLLMs, a phenomenon termed emergent misalignment (EM). While concerning, these\nfindings were limited to finetuning and activa...",
    "collected_at": "2025-10-20T16:06:55.471487",
    "arxiv_id": null,
    "categories": null,
    "thumbnail_url": null,
    "embed_supported": null,
    "view_count": null
  }
];
    </script>
    <script src="../assets/js/script.js"></script>
</body>
</html>